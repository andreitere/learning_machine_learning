{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This example uses a dataset in romanian language to train and evaluate a sentiment analysis model.\n",
    "\n",
    "We use datasets library to load the \"ro_sent\" dataset from the public [HuggingFace](https://huggingface.co/) repository.\n",
    "\n",
    "The dataset is composed of phrases labeled as positive/negative (1/0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset ro_sent (/Users/andreiterecoasa/.cache/huggingface/datasets/ro_sent/default/1.0.0/45a32ef8c65b2b93a8602bd67cc295b1e760cf89cb32de2e3805999fafaa1c96)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9ae9cf23dd24137a4ad30428acc547c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the dataset\n",
    "ro_sentence_sentiment = load_dataset(\"ro_sent\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# the downloaded dataset is already split between train and test sets so we will use these.\n",
    "# We could also merge them and use train_test_split from sklearn.model_selection to split by custom ratio\n",
    "train = ro_sentence_sentiment[\"train\"].to_pandas().drop(columns=[\"original_id\", \"id\"])\n",
    "test = ro_sentence_sentiment[\"test\"].to_pandas().drop(columns=[\"original_id\", \"id\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# A machine learning model works with numbers. It finds patterns amongts the features and that's how it's trained and then can predict.\n",
    "# To be able to train the model we first have to transform the sentences to numbers somehow\n",
    "# To do this we will use CountVectorizer from sklearn.feature_extraction.text.\n",
    "# From the docs: CountVectorizer converts a collection of text documents to a matrix of token counts\n",
    "vectorizer = CountVectorizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "CountVectorizer()"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .fit method helps the vectorizer learn all the tokens (words) in the dataset\n",
    "vectorizer.fit(train[\"sentence\"].append(test[\"sentence\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Preparing the inputs for the model training.\n",
    "\n",
    "# previously the vectorizer learned the vocabulary of the dataset. Now we actually apply the transformation to the train set (tokens to matrix counts)\n",
    "\n",
    "X_train = vectorizer.transform(train[\"sentence\"])\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "# X_ and y_ are common notations for model input. X_ denotes the training vector and y_ is the target vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# For the model, we will use LogisticRegression.\n",
    "# This models helps solving problems where output is one of two (yes/no, true/false, 1/0, etc)\n",
    "\n",
    "sentiment_model = LogisticRegression(max_iter=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=1000)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data into the model.\n",
    "# basically this represents model training\n",
    "sentiment_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'doamne ce bun a fost kfc-ul asta' ====> Positive\n",
      "'saramalele sunt ok' ====> Positive\n",
      "'e o vreme de cacat. nu vezi nimic' ====> Positive\n"
     ]
    }
   ],
   "source": [
    "# Now we're ready to make our first prediction\n",
    "sent_map = [\"Negative\", \"Positive\"]\n",
    "# our input phrases\n",
    "input_phrases = [\"doamne ce bun a fost kfc-ul asta\", \"saramalele sunt ok\", \"e o vreme de cacat. nu vezi nimic afara\"]\n",
    "# transforming the input to matrix counts as we did before for the training data\n",
    "my_test = vectorizer.transform(input_phrases)\n",
    "\n",
    "# predict the labels for the input_phrases\n",
    "res = sentiment_model.predict(my_test)\n",
    "for index, _r in enumerate(res):\n",
    "    print(f\"'{input_phrases[index]}' ====> {sent_map[_r]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'Accuracy is 0.8529759200363471'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the .score method on the LogisticModel to test the accuracy of the model\n",
    "# We first we use the vectorizer to transform the test set and then we simply call the .score method.\n",
    "X_test = vectorizer.transform(test[\"sentence\"])\n",
    "acc = sentiment_model.score(X_test, test[\"label\"])\n",
    "f\"Accuracy is {acc}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While an 85% accuracy looks good and you'll find plenty examples for which the prediction is correct bear in mind that this is just a simple example and does not offer a complete solution."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}